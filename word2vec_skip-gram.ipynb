{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Este código permite preprocesar cualquier texto raw y vectorizarlo con Word2vec. En este caso se trabajo Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-c284f7c8b6c1>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828adffe88444c4a9918e889cea4db83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -U gensim\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "folder = 'Word-embeddings/'\n",
    "\n",
    "#files=[]\n",
    "## r=root, d=directories, f = files\n",
    "#for r, d, f in os.walk(folder):\n",
    "#    for file in f:\n",
    "#        #print(os.path.join(r, file))\n",
    "#        files.append(os.path.join(r, file))\n",
    "\n",
    "#data = \"\"\n",
    "#for i, f in enumerate(files):\n",
    "#    #with open(f) as fp:\n",
    "#    with io.open(f, 'r', encoding='latin-1') as fp:\n",
    "#        data += fp.read()\n",
    "#    data += '\\n'\n",
    "\n",
    "#with open (folder + 'ancora_all.txt', 'w') as fp:\n",
    "#with io.open(folder + \"wiki_raw_all.txt\", 'w', encoding='utf8') as fp:\n",
    "#    fp.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-60d9ab819fc6>:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for x in tqdm(f, total=num_lines):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105f961ba0be43c6938f41d1b4a26524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=40040.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. Oraciones en total dataset:  36817 \n",
      "\n",
      "['LA', 'SANTA', 'BIBLIA']\n"
     ]
    }
   ],
   "source": [
    "all_sentences = []\n",
    "#f = open(folder + \"ancora_all.txt\", \"rb\")\n",
    "num_lines = sum(1 for line in open(\"labiblia2.txt\",'r'))\n",
    "\n",
    "f = io.open(\"labiblia2.txt\", 'r', encoding='utf8')\n",
    "\n",
    "for x in tqdm(f, total=num_lines):\n",
    "    tokens = word_tokenize(x, \"spanish\")\n",
    "    if len(tokens) != 0:\n",
    "        if x[:4] != '<doc' and x[:5] != '</doc':\n",
    "            all_sentences.append(tokens)\n",
    "\n",
    "print('No. Oraciones en total dataset: ', len(all_sentences), '\\n')\n",
    "\n",
    "print(all_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8e262d700f91>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, sent in tqdm(enumerate(all_sentences), total=num_lines2):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6733d24ffe4fc3a39914e8a34768f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=36817.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[['VERSIÓN', 'BIBLIA', 'DE', 'JERUSALÉN', ',', '1976'], ['GÉNESIS'], ['Génesis', '1'], ['1', 'En', 'el', 'principio', 'creó', 'Dios', 'los', 'cielos', 'y', 'la', 'tierra', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "diccionario = dict()\n",
    "\n",
    "num_lines2 = len(all_sentences)\n",
    "\n",
    "for i, sent in tqdm(enumerate(all_sentences), total=num_lines2):\n",
    "    sente = []\n",
    "    for k, word in enumerate(sent):\n",
    "        sente.append(word)\n",
    "        if word not in diccionario:\n",
    "            diccionario[word] = 1\n",
    "        else:\n",
    "            diccionario[word] += 1\n",
    "\n",
    "    sentences.append(sente)\n",
    "        \n",
    "print(sentences[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de oraciones presentes en el corpus: 36817\n",
      "                 numero de palabras unicas: 38521\n"
     ]
    }
   ],
   "source": [
    "print (\"numero de oraciones presentes en el corpus: \" + str(len(sentences)))\n",
    "print (\"                 numero de palabras unicas: \" + str(len(diccionario)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "num_features = 300                      #Dimensionality of the resulting word vectors\n",
    "min_word_count = 1                            #Minimum word count threshold\n",
    "num_workers = multiprocessing.cpu_count()     #Number of threads to run in parallel\n",
    "context_size = 8                              #Context window length\n",
    "seed = 1                                      #Seed for the RNG, to make the result reproducible\n",
    "model = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")\n",
    "model.wv.save_word2vec_format('word2vec_skip-gram_model_' + str(300) +  '.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('concibió', 0.9710509777069092), ('Raquel', 0.9517586827278137), ('suegro', 0.9482018351554871), ('Labán', 0.9418478012084961), ('Tobías', 0.9392855763435364), ('Simón', 0.9385716915130615), ('Absalón', 0.9366384744644165), ('Bilhá', 0.9332038164138794), ('Ragüel', 0.9318463206291199), ('Jehú', 0.9318000674247742)]\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv['Rebeca']  # get numpy vector of a word\n",
    "sims = model.wv.most_similar('Rebeca', topn=10)  # get other similar words\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Moisés', 0.9016028642654419),\n",
       " ('David', 0.8638561367988586),\n",
       " ('Saúl', 0.8478865623474121),\n",
       " ('entonces', 0.8205558657646179),\n",
       " ('Faraón', 0.8175210952758789),\n",
       " ('enseñaba', 0.7914533019065857),\n",
       " ('Jeremías', 0.7847006320953369),\n",
       " ('Joab', 0.7771956324577332),\n",
       " ('salir', 0.7768556475639343),\n",
       " ('Arsaces', 0.7719936966896057)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Jesús')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
