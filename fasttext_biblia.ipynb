{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de la vectorización  fasttext del texto de la biblia, se limpia un texto se consigue un archivo vectorizado y se realizan consultas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Labiblia-1.txt', 'rb') as source_file:\n",
    "  with open('labiblia2.txt', 'w+b') as dest_file:\n",
    "    contents = source_file.read()\n",
    "    dest_file.write(contents.decode('utf-16').encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# common_texts es el texto original de Gensim que es una lista de listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "common_texts[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lectura de texto y creación de la lista de sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U gensim\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from gensim.models import FastText\n",
    "\n",
    "data_set = []\n",
    "\n",
    "f = open('labiblia2.txt', mode='r', encoding='utf-8').readlines()\n",
    "\n",
    "for line in f:\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    data_set.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización de las sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['VERSIÓN', 'BIBLIA', 'DE', 'JERUSALÉN,', '1976'], ['GÉNESIS'], ['Génesis', '1'], ['1', 'En', 'el', 'principio', 'creó', 'Dios', 'los', 'cielos', 'y', 'la', 'tierra.'], ['2', 'La', 'tierra', 'era', 'caos', 'y', 'confusión', 'y', 'oscuridad', 'por', 'encima', 'del', 'abismo,', 'y', 'un', 'viento', 'de', 'Dios', 'aleteaba', 'por', 'encima', 'de', 'las', 'aguas.'], ['3', 'Dijo', 'Dios:', '«Haya', 'luz»,', 'y', 'hubo', 'luz.'], ['4', 'Vio', 'Dios', 'que', 'la', 'luz', 'estaba', 'bien,', 'y', 'apartó', 'Dios', 'la', 'luz', 'de', 'la', 'oscuridad;'], ['5', 'y', 'llamó', 'Dios', 'a', 'la', 'luz', '«día»,', 'y', 'a', 'la', 'oscuridad', 'la', 'llamó', '«noche».', 'Y', 'atardeció', 'y', 'amaneció:', 'día', 'primero.'], ['6', 'Dijo', 'Dios:', '«Haya', 'un', 'firmamento', 'por', 'en', 'medio', 'de', 'las', 'aguas,', 'que', 'las', 'aparte', 'unas', 'de', 'otras.»']]\n",
      "No. Oraciones en train dataset:  36945\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sentences = []\n",
    "diccionario = dict()\n",
    "\n",
    "for i, sent in enumerate(data_set):\n",
    "    if i >= 0:\n",
    "        if len(sent) > 1:\n",
    "            sente = sent.split()\n",
    "            sentences.append(sente)\n",
    "           # tokens = word_tokenize(sentences)\n",
    "            \n",
    "print(sentences[1:10])\n",
    "print('No. Oraciones en train dataset: ', len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Oraciones en train dataset:  36945\n",
      "['LA SANTA BIBLIA', '', '']\n"
     ]
    }
   ],
   "source": [
    "print('No. Oraciones en train dataset: ', len(sentences))\n",
    "\n",
    "print(data_set[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['VERSIÓN', 'BIBLIA', 'DE', 'JERUSALÉN,', '1976'], ['GÉNESIS']]\n",
      "['14', 'Es', 'decir', 'que', 'hoy', 'me', 'echas', 'de', 'este', 'suelo', 'y', 'he', 'de', 'esconderme', 'de', 'tu', 'presencia,', 'convertido', 'en', 'vagabundo', 'errante', 'por', 'la', 'tierra,', 'y', 'cualquiera', 'que', 'me', 'encuentre', 'me', 'matará.»']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1:3])\n",
    "print(sentences[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de oraciones presentes en el corpus: 36945\n"
     ]
    }
   ],
   "source": [
    "print (\"numero de oraciones presentes en el corpus: \" + str(len(sentences)))\n",
    "#print (\"                 numero de palabras unicas: \" + str(len(diccionario)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Características de la construcción del vector usando fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [300]                      #Dimensionality of the resulting word vectors\n",
    "min_word_count = 1                        #Minimum word count threshold\n",
    "num_workers = multiprocessing.cpu_count() #Number of threads to run in parallel\n",
    "context_size = 5                          #Context window length\n",
    "seed = 1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formato del archivo de salida para fasttext sobre un archivo raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in num_features:\n",
    "    fasttext_model = FastText(\n",
    "        sentences=sentences,\n",
    "        vector_size=300,\n",
    "        window=context_size,\n",
    "        min_count=min_word_count,\n",
    "        workers=num_workers, \n",
    "        sg=0                              #cbow\n",
    "    )\n",
    "\n",
    "    fasttext_model.wv.save_word2vec_format('./biblia_fasttext_cbow_model_' + str(p) +  '.txt', binary=False)\n",
    "    \n",
    "    #del fasttext_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas con fasttext sobre el raw de la biblia   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model1 = FastText(sentences=sentences, vector_size=300,window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims1 = model1.wv.most_similar('Isaac', topn=10)  # get other similar words\n",
    "print(sims1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
